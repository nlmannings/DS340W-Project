{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# THIS NOTEBOOK MUST BE RAN LOCALLY ON A MAC FOR ALL DEPENDENCIES TO INSTALL CORRECTLY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run this to install the pyenv version manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install pyenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Once it has successfully installed, install all the reqiured python version with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pyenv install 3.11.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### And creeate a virtual envrionment and activate it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting filelock<4,>=3.12.2 (from virtualenv)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /Users/nate/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from virtualenv) (4.5.0)\n",
            "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: distlib, filelock, virtualenv\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [virtualenv]3\u001b[0m [virtualenv]\n",
            "\u001b[1A\u001b[2KSuccessfully installed distlib-0.4.0 filelock-3.20.0 virtualenv-20.35.4\n",
            "created virtual environment CPython3.11.9.final.0-64 in 873ms\n",
            "  creator CPython3Posix(dest=/Users/nate/.pyenv/versions/3.11.9/envs/aaaaa, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, via=copy, app_data_dir=/Users/nate/Library/Application Support/virtualenv)\n",
            "    added seed packages: pip==25.3, setuptools==80.9.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ],
      "source": [
        "!pyenv virtualenv 3.11.9 group48\n",
        "!pyenv activate group48\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now you should be able to install the necessary packages under the python binary that was just created using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install numpy pandas scikit-learn tensorflow pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!~/.pyenv/versions/3.11.9/bin/python3 -m pip install numpy pandas scikit-learn tensorflow pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import layers, models, regularizers, callbacks, optimizers\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEzxgz-2oBAe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "KERNEL_SIZES = [(3,3), (5,5), (7,7)]\n",
        "N_SPLITS = 5  # Stratified K-Fold splits\n",
        "RANDOM_SEED = 42\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "DROPOUT_P = 0.1\n",
        "RESULTS_CSV = \"kernel_search_results.csv\"\n",
        "TARGET_SIZE = (224, 224)  # as in your loader\n",
        "POS_LABEL = 1  # schizophrenia class is positive\n",
        "VERBOSE = 1\n",
        "\n",
        "\n",
        "healthy_save_path = './Data/healthy'\n",
        "schizophrenia_save_path = './Data/schizophrenic'\n",
        "\n",
        "healthy_folder = healthy_save_path\n",
        "schizophrenia_folder = schizophrenia_save_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading healthy images...\n",
            "Loading schizophrenia images...\n",
            "Loaded dataset: X.shape=(1828, 224, 224, 3), y.shape=(1828,), #HC=948, #SCZ=880\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load & preprocess images (your loader adapted)\n",
        "def load_images(folder, label_for_folder):\n",
        "    images, labels = [], []\n",
        "    if not os.path.exists(folder):\n",
        "        raise FileNotFoundError(f\"Folder not found: {folder}\")\n",
        "    for filename in sorted(os.listdir(folder)):\n",
        "        if filename.lower().endswith(\".png\"):\n",
        "            img = image.load_img(os.path.join(folder, filename), target_size=TARGET_SIZE)\n",
        "            img_array = image.img_to_array(img) / 255.0\n",
        "            images.append(img_array)\n",
        "            labels.append(label_for_folder)\n",
        "    if len(images) == 0:\n",
        "        raise ValueError(f\"No PNG images found in folder: {folder}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "print(\"Loading healthy images...\")\n",
        "X_healthy, y_healthy = load_images(healthy_folder, 0)\n",
        "print(\"Loading schizophrenia images...\")\n",
        "X_schizophrenia, y_schizophrenia = load_images(schizophrenia_folder, 1)\n",
        "\n",
        "# Merge and shuffle\n",
        "X = np.concatenate((X_healthy, X_schizophrenia), axis=0)\n",
        "y = np.concatenate((y_healthy, y_schizophrenia), axis=0)\n",
        "rng = np.random.RandomState(RANDOM_SEED)\n",
        "perm = rng.permutation(len(y))\n",
        "X = X[perm]\n",
        "y = y[perm]\n",
        "\n",
        "print(f\"Loaded dataset: X.shape={X.shape}, y.shape={y.shape}, #HC={np.sum(y==0)}, #SCZ={np.sum(y==1)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def build_model(kernel_size_1=(3,3), kernel_size_2=(3,3), input_shape=None, dropout_p=0.1):\n",
        "    if input_shape is None:\n",
        "        input_shape = X.shape[1:]\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(filters=4, kernel_size=kernel_size_1, strides=(2,2),\n",
        "                      padding='same', activation='relu')(inp)\n",
        "    x = layers.MaxPool2D(pool_size=(2,2))(x)\n",
        "    x = layers.Dropout(dropout_p)(x)\n",
        "\n",
        "    x = layers.Conv2D(filters=8, kernel_size=kernel_size_2, strides=(2,2),\n",
        "                      padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = layers.GlobalMaxPool2D()(x)\n",
        "    x = layers.Dropout(dropout_p)(x)\n",
        "\n",
        "    x = layers.Dense(50, activation='relu')(x)\n",
        "    out = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=out)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Try to allow GPU memory growth if GPUs available\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for g in gpus:\n",
        "            tf.config.experimental.set_memory_growth(g, True)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Kernel run 1/9: conv1=(3, 3), conv2=(3, 3) ===\n",
            "  Fold 1/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - accuracy: 0.5410 - loss: 0.7276 - val_accuracy: 0.6776 - val_loss: 0.7038\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6347 - loss: 0.6526 - val_accuracy: 0.6721 - val_loss: 0.6784\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6648 - loss: 0.6112 - val_accuracy: 0.6967 - val_loss: 0.5960\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6908 - loss: 0.5732 - val_accuracy: 0.6694 - val_loss: 0.6507\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.6970 - loss: 0.5626 - val_accuracy: 0.6694 - val_loss: 0.6445\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7031 - loss: 0.5570 - val_accuracy: 0.6967 - val_loss: 0.5589\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7079 - loss: 0.5501 - val_accuracy: 0.7022 - val_loss: 0.5745\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7161 - loss: 0.5482 - val_accuracy: 0.6885 - val_loss: 0.5935\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7189 - loss: 0.5400 - val_accuracy: 0.6995 - val_loss: 0.5741\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7155 - loss: 0.5310 - val_accuracy: 0.6639 - val_loss: 0.6319\n",
            "    fold bal_acc=0.7068, prec=0.6173, rec=0.9716, f1=0.7550\n",
            "  Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.5417 - loss: 0.7121 - val_accuracy: 0.6667 - val_loss: 0.6904\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6238 - loss: 0.6439 - val_accuracy: 0.6639 - val_loss: 0.6793\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.6642 - loss: 0.6128 - val_accuracy: 0.6913 - val_loss: 0.6263\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.6758 - loss: 0.5809 - val_accuracy: 0.6858 - val_loss: 0.6277\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7052 - loss: 0.5642 - val_accuracy: 0.6776 - val_loss: 0.6178\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6997 - loss: 0.5570 - val_accuracy: 0.6475 - val_loss: 0.6699\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7059 - loss: 0.5526 - val_accuracy: 0.6612 - val_loss: 0.6422\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7066 - loss: 0.5455 - val_accuracy: 0.6639 - val_loss: 0.6365\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7073 - loss: 0.5439 - val_accuracy: 0.6503 - val_loss: 0.6569\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7230 - loss: 0.5324 - val_accuracy: 0.6612 - val_loss: 0.6209\n",
            "    fold bal_acc=0.6895, prec=0.5986, rec=1.0000, f1=0.7489\n",
            "  Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.5923 - loss: 0.7206 - val_accuracy: 0.6749 - val_loss: 0.6938\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.6320 - loss: 0.6612 - val_accuracy: 0.7322 - val_loss: 0.6092\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6648 - loss: 0.6166 - val_accuracy: 0.7295 - val_loss: 0.5722\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6881 - loss: 0.5734 - val_accuracy: 0.7322 - val_loss: 0.5477\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7045 - loss: 0.5608 - val_accuracy: 0.7350 - val_loss: 0.5344\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6970 - loss: 0.5608 - val_accuracy: 0.7377 - val_loss: 0.5314\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7141 - loss: 0.5504 - val_accuracy: 0.7377 - val_loss: 0.5271\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.7093 - loss: 0.5447 - val_accuracy: 0.7322 - val_loss: 0.5547\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7278 - loss: 0.5344 - val_accuracy: 0.7377 - val_loss: 0.5332\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7332 - loss: 0.5240 - val_accuracy: 0.7377 - val_loss: 0.5199\n",
            "    fold bal_acc=0.7467, prec=0.6504, rec=0.9830, f1=0.7828\n",
            "  Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - accuracy: 0.5338 - loss: 0.7230 - val_accuracy: 0.5863 - val_loss: 0.7089\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.5995 - loss: 0.6683 - val_accuracy: 0.6658 - val_loss: 0.6405\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6603 - loss: 0.6022 - val_accuracy: 0.7178 - val_loss: 0.6067\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7047 - loss: 0.5705 - val_accuracy: 0.7151 - val_loss: 0.5932\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7047 - loss: 0.5548 - val_accuracy: 0.6466 - val_loss: 0.6663\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7136 - loss: 0.5469 - val_accuracy: 0.7151 - val_loss: 0.5665\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7266 - loss: 0.5292 - val_accuracy: 0.6877 - val_loss: 0.6012\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7204 - loss: 0.5371 - val_accuracy: 0.6685 - val_loss: 0.6221\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7389 - loss: 0.5194 - val_accuracy: 0.6959 - val_loss: 0.5886\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7457 - loss: 0.5148 - val_accuracy: 0.6740 - val_loss: 0.6173\n",
            "    fold bal_acc=0.7249, prec=0.6286, rec=1.0000, f1=0.7719\n",
            "  Fold 5/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.5325 - loss: 0.7249 - val_accuracy: 0.4959 - val_loss: 0.7179\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.6159 - loss: 0.6717 - val_accuracy: 0.6493 - val_loss: 0.6420\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6753 - loss: 0.5914 - val_accuracy: 0.6959 - val_loss: 0.5840\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7027 - loss: 0.5570 - val_accuracy: 0.7096 - val_loss: 0.5967\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7102 - loss: 0.5531 - val_accuracy: 0.7123 - val_loss: 0.5670\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.7088 - loss: 0.5405 - val_accuracy: 0.7123 - val_loss: 0.5679\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.7170 - loss: 0.5335 - val_accuracy: 0.7041 - val_loss: 0.5895\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7184 - loss: 0.5296 - val_accuracy: 0.6932 - val_loss: 0.6050\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7321 - loss: 0.5183 - val_accuracy: 0.7041 - val_loss: 0.5816\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.7191 - loss: 0.5211 - val_accuracy: 0.7068 - val_loss: 0.5725\n",
            "    fold bal_acc=0.7210, prec=0.6320, rec=0.9659, f1=0.7640\n",
            "\n",
            "=== Kernel run 2/9: conv1=(3, 3), conv2=(5, 5) ===\n",
            "  Fold 1/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.4925 - loss: 0.7273 - val_accuracy: 0.5956 - val_loss: 0.7059\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.5301 - loss: 0.6889 - val_accuracy: 0.7295 - val_loss: 0.6594\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.6703 - loss: 0.6023 - val_accuracy: 0.7295 - val_loss: 0.5720\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.7189 - loss: 0.5551 - val_accuracy: 0.7268 - val_loss: 0.5542\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.7127 - loss: 0.5405 - val_accuracy: 0.7268 - val_loss: 0.5409\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7326 - loss: 0.5228 - val_accuracy: 0.7268 - val_loss: 0.5314\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.7305 - loss: 0.5296 - val_accuracy: 0.7104 - val_loss: 0.5867\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.7339 - loss: 0.5178 - val_accuracy: 0.7268 - val_loss: 0.5392\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.7339 - loss: 0.5102 - val_accuracy: 0.7077 - val_loss: 0.5649\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.7585 - loss: 0.5012 - val_accuracy: 0.7705 - val_loss: 0.5160\n",
            "    fold bal_acc=0.7737, prec=0.7190, rec=0.8580, f1=0.7824\n",
            "  Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5643 - loss: 0.7095 - val_accuracy: 0.6694 - val_loss: 0.6754\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.6532 - loss: 0.6144 - val_accuracy: 0.6749 - val_loss: 0.6498\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.6956 - loss: 0.5686 - val_accuracy: 0.6831 - val_loss: 0.5840\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.6997 - loss: 0.5510 - val_accuracy: 0.6721 - val_loss: 0.6037\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7031 - loss: 0.5445 - val_accuracy: 0.6776 - val_loss: 0.5930\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7127 - loss: 0.5359 - val_accuracy: 0.6967 - val_loss: 0.5714\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7189 - loss: 0.5402 - val_accuracy: 0.6694 - val_loss: 0.5927\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7202 - loss: 0.5321 - val_accuracy: 0.6940 - val_loss: 0.5588\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.7257 - loss: 0.5249 - val_accuracy: 0.6694 - val_loss: 0.5919\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7216 - loss: 0.5249 - val_accuracy: 0.6721 - val_loss: 0.6111\n",
            "    fold bal_acc=0.7046, prec=0.6135, rec=0.9830, f1=0.7555\n",
            "  Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.5561 - loss: 0.7186 - val_accuracy: 0.5546 - val_loss: 0.6827\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.6300 - loss: 0.6511 - val_accuracy: 0.7295 - val_loss: 0.5801\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.6867 - loss: 0.5807 - val_accuracy: 0.7322 - val_loss: 0.5438\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.6984 - loss: 0.5582 - val_accuracy: 0.7350 - val_loss: 0.5239\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.7004 - loss: 0.5480 - val_accuracy: 0.7322 - val_loss: 0.5169\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7079 - loss: 0.5356 - val_accuracy: 0.7404 - val_loss: 0.5082\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.7244 - loss: 0.5377 - val_accuracy: 0.7322 - val_loss: 0.5117\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7182 - loss: 0.5255 - val_accuracy: 0.7432 - val_loss: 0.4998\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7230 - loss: 0.5242 - val_accuracy: 0.7459 - val_loss: 0.4947\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.7298 - loss: 0.5309 - val_accuracy: 0.7404 - val_loss: 0.4962\n",
            "    fold bal_acc=0.7544, prec=0.6590, rec=0.9773, f1=0.7872\n",
            "  Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.5318 - loss: 0.7186 - val_accuracy: 0.5753 - val_loss: 0.7001\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.5721 - loss: 0.6914 - val_accuracy: 0.5836 - val_loss: 0.6789\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.5988 - loss: 0.6711 - val_accuracy: 0.6356 - val_loss: 0.6538\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.6500 - loss: 0.6380 - val_accuracy: 0.6986 - val_loss: 0.6034\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.6883 - loss: 0.5681 - val_accuracy: 0.7205 - val_loss: 0.5329\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7061 - loss: 0.5416 - val_accuracy: 0.7178 - val_loss: 0.5180\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7403 - loss: 0.5204 - val_accuracy: 0.7205 - val_loss: 0.4987\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.7526 - loss: 0.5075 - val_accuracy: 0.7507 - val_loss: 0.5079\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7478 - loss: 0.5145 - val_accuracy: 0.7726 - val_loss: 0.4959\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.7532 - loss: 0.5036 - val_accuracy: 0.7534 - val_loss: 0.5164\n",
            "    fold bal_acc=0.7785, prec=0.6946, rec=0.9432, f1=0.8000\n",
            "  Fold 5/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.5256 - loss: 0.7169 - val_accuracy: 0.5178 - val_loss: 0.6966\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.5871 - loss: 0.6691 - val_accuracy: 0.6932 - val_loss: 0.6330\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6459 - loss: 0.6043 - val_accuracy: 0.7151 - val_loss: 0.5925\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.7020 - loss: 0.5581 - val_accuracy: 0.7205 - val_loss: 0.5664\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.7239 - loss: 0.5305 - val_accuracy: 0.7288 - val_loss: 0.5537\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7177 - loss: 0.5329 - val_accuracy: 0.7233 - val_loss: 0.5441\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7293 - loss: 0.5306 - val_accuracy: 0.7260 - val_loss: 0.5500\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7307 - loss: 0.5199 - val_accuracy: 0.7123 - val_loss: 0.5622\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7334 - loss: 0.5203 - val_accuracy: 0.7260 - val_loss: 0.5420\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.7286 - loss: 0.5161 - val_accuracy: 0.7507 - val_loss: 0.5272\n",
            "    fold bal_acc=0.7577, prec=0.6693, rec=0.9545, f1=0.7869\n",
            "\n",
            "=== Kernel run 3/9: conv1=(3, 3), conv2=(7, 7) ===\n",
            "  Fold 1/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.5144 - loss: 0.7173 - val_accuracy: 0.6257 - val_loss: 0.7016\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.5520 - loss: 0.6887 - val_accuracy: 0.5710 - val_loss: 0.6572\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.6477 - loss: 0.6225 - val_accuracy: 0.6776 - val_loss: 0.5750\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.7326 - loss: 0.5456 - val_accuracy: 0.7322 - val_loss: 0.5233\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.7538 - loss: 0.5117 - val_accuracy: 0.7732 - val_loss: 0.5143\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.7565 - loss: 0.5155 - val_accuracy: 0.7705 - val_loss: 0.5136\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7722 - loss: 0.5022 - val_accuracy: 0.8005 - val_loss: 0.4818\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7818 - loss: 0.4847 - val_accuracy: 0.7951 - val_loss: 0.4791\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7818 - loss: 0.4902 - val_accuracy: 0.7896 - val_loss: 0.4816\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.7880 - loss: 0.4795 - val_accuracy: 0.7514 - val_loss: 0.5234\n",
            "    fold bal_acc=0.7982, prec=0.7416, rec=0.8807, f1=0.8052\n",
            "  Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 85ms/step - accuracy: 0.5616 - loss: 0.7128 - val_accuracy: 0.5109 - val_loss: 0.6753\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.6436 - loss: 0.6139 - val_accuracy: 0.6448 - val_loss: 0.5970\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7120 - loss: 0.5523 - val_accuracy: 0.7049 - val_loss: 0.5588\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7367 - loss: 0.5320 - val_accuracy: 0.7022 - val_loss: 0.5578\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - accuracy: 0.7216 - loss: 0.5358 - val_accuracy: 0.7268 - val_loss: 0.5387\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.7565 - loss: 0.5135 - val_accuracy: 0.7541 - val_loss: 0.5243\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.7715 - loss: 0.4968 - val_accuracy: 0.7678 - val_loss: 0.5101\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7811 - loss: 0.4926 - val_accuracy: 0.7541 - val_loss: 0.5210\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7756 - loss: 0.5016 - val_accuracy: 0.7650 - val_loss: 0.5165\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7798 - loss: 0.4860 - val_accuracy: 0.7596 - val_loss: 0.5106\n",
            "    fold bal_acc=0.7744, prec=0.6872, rec=0.9489, f1=0.7971\n",
            "  Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.4979 - loss: 0.7230 - val_accuracy: 0.5191 - val_loss: 0.7004\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.5424 - loss: 0.6909 - val_accuracy: 0.6940 - val_loss: 0.6570\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.6594 - loss: 0.6086 - val_accuracy: 0.7158 - val_loss: 0.5431\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7018 - loss: 0.5542 - val_accuracy: 0.7377 - val_loss: 0.5174\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7079 - loss: 0.5398 - val_accuracy: 0.7404 - val_loss: 0.5154\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.7182 - loss: 0.5374 - val_accuracy: 0.7350 - val_loss: 0.5219\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.7073 - loss: 0.5502 - val_accuracy: 0.7404 - val_loss: 0.5162\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7278 - loss: 0.5258 - val_accuracy: 0.7350 - val_loss: 0.5362\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7202 - loss: 0.5365 - val_accuracy: 0.7432 - val_loss: 0.5070\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7223 - loss: 0.5262 - val_accuracy: 0.7350 - val_loss: 0.5206\n",
            "    fold bal_acc=0.7522, prec=0.6541, rec=0.9886, f1=0.7873\n",
            "  Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - accuracy: 0.5468 - loss: 0.7263 - val_accuracy: 0.5671 - val_loss: 0.6972\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6487 - loss: 0.6660 - val_accuracy: 0.8000 - val_loss: 0.5990\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7252 - loss: 0.5873 - val_accuracy: 0.7945 - val_loss: 0.5297\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.7423 - loss: 0.5493 - val_accuracy: 0.7945 - val_loss: 0.5306\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7450 - loss: 0.5363 - val_accuracy: 0.8110 - val_loss: 0.5045\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7505 - loss: 0.5200 - val_accuracy: 0.8247 - val_loss: 0.4927\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7457 - loss: 0.5148 - val_accuracy: 0.7753 - val_loss: 0.4931\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.7532 - loss: 0.5149 - val_accuracy: 0.7945 - val_loss: 0.4695\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7649 - loss: 0.4981 - val_accuracy: 0.8027 - val_loss: 0.4646\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.7608 - loss: 0.5034 - val_accuracy: 0.8110 - val_loss: 0.4570\n",
            "    fold bal_acc=0.8139, prec=0.7560, rec=0.8977, f1=0.8208\n",
            "  Fold 5/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 150ms/step - accuracy: 0.5571 - loss: 0.7072 - val_accuracy: 0.6932 - val_loss: 0.6721\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.6726 - loss: 0.6040 - val_accuracy: 0.7041 - val_loss: 0.5859\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.7047 - loss: 0.5613 - val_accuracy: 0.6904 - val_loss: 0.5925\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7088 - loss: 0.5444 - val_accuracy: 0.7205 - val_loss: 0.5519\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7259 - loss: 0.5351 - val_accuracy: 0.7205 - val_loss: 0.5501\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7280 - loss: 0.5287 - val_accuracy: 0.7288 - val_loss: 0.5428\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.7191 - loss: 0.5241 - val_accuracy: 0.7205 - val_loss: 0.5408\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.7321 - loss: 0.5208 - val_accuracy: 0.7205 - val_loss: 0.5435\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.7259 - loss: 0.5169 - val_accuracy: 0.7205 - val_loss: 0.5325\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.7321 - loss: 0.5073 - val_accuracy: 0.7288 - val_loss: 0.5336\n",
            "    fold bal_acc=0.7290, prec=0.6391, rec=0.9659, f1=0.7692\n",
            "\n",
            "=== Kernel run 4/9: conv1=(5, 5), conv2=(3, 3) ===\n",
            "  Fold 1/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.5356 - loss: 0.7148 - val_accuracy: 0.6557 - val_loss: 0.6840\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.6751 - loss: 0.6408 - val_accuracy: 0.7322 - val_loss: 0.5932\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7086 - loss: 0.5812 - val_accuracy: 0.7350 - val_loss: 0.5649\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.7278 - loss: 0.5453 - val_accuracy: 0.7295 - val_loss: 0.5390\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7387 - loss: 0.5247 - val_accuracy: 0.7486 - val_loss: 0.5417\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 96ms/step - accuracy: 0.7387 - loss: 0.5259 - val_accuracy: 0.6940 - val_loss: 0.5833\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.7442 - loss: 0.5188 - val_accuracy: 0.7240 - val_loss: 0.5372\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.7572 - loss: 0.5066 - val_accuracy: 0.7678 - val_loss: 0.5223\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - accuracy: 0.7531 - loss: 0.5042 - val_accuracy: 0.7131 - val_loss: 0.5546\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.7538 - loss: 0.5121 - val_accuracy: 0.7104 - val_loss: 0.5503\n",
            "    fold bal_acc=0.7744, prec=0.6872, rec=0.9489, f1=0.7971\n",
            "  Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 0.4850 - loss: 0.7656 - val_accuracy: 0.5191 - val_loss: 0.7204\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - accuracy: 0.5233 - loss: 0.7151 - val_accuracy: 0.5191 - val_loss: 0.7083\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 99ms/step - accuracy: 0.5185 - loss: 0.7035 - val_accuracy: 0.5191 - val_loss: 0.6965\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.5896 - loss: 0.6789 - val_accuracy: 0.7022 - val_loss: 0.6456\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.6477 - loss: 0.6403 - val_accuracy: 0.6995 - val_loss: 0.6174\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.6744 - loss: 0.6229 - val_accuracy: 0.7077 - val_loss: 0.6004\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.6724 - loss: 0.6093 - val_accuracy: 0.7049 - val_loss: 0.5927\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.6703 - loss: 0.6110 - val_accuracy: 0.7295 - val_loss: 0.5914\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.6840 - loss: 0.5967 - val_accuracy: 0.7295 - val_loss: 0.5741\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.7011 - loss: 0.5906 - val_accuracy: 0.7240 - val_loss: 0.5668\n",
            "    fold bal_acc=0.7265, prec=0.6847, rec=0.7898, f1=0.7335\n",
            "  Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 103ms/step - accuracy: 0.6040 - loss: 0.7054 - val_accuracy: 0.6967 - val_loss: 0.6747\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53108s\u001b[0m 584s/step - accuracy: 0.6457 - loss: 0.6613 - val_accuracy: 0.6885 - val_loss: 0.6428\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - accuracy: 0.6731 - loss: 0.6418 - val_accuracy: 0.6885 - val_loss: 0.6270\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.6936 - loss: 0.6143 - val_accuracy: 0.7049 - val_loss: 0.5993\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - accuracy: 0.6922 - loss: 0.5999 - val_accuracy: 0.7049 - val_loss: 0.5814\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.7031 - loss: 0.5786 - val_accuracy: 0.7377 - val_loss: 0.5489\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.7339 - loss: 0.5550 - val_accuracy: 0.7459 - val_loss: 0.5342\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - accuracy: 0.7346 - loss: 0.5394 - val_accuracy: 0.7268 - val_loss: 0.5550\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.7216 - loss: 0.5400 - val_accuracy: 0.7541 - val_loss: 0.5161\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.7278 - loss: 0.5346 - val_accuracy: 0.7459 - val_loss: 0.5389\n",
            "    fold bal_acc=0.7596, prec=0.6853, rec=0.9034, f1=0.7794\n",
            "  Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 107ms/step - accuracy: 0.5338 - loss: 0.7268 - val_accuracy: 0.5288 - val_loss: 0.7024\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - accuracy: 0.5960 - loss: 0.6695 - val_accuracy: 0.6849 - val_loss: 0.6216\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 71ms/step - accuracy: 0.6432 - loss: 0.6171 - val_accuracy: 0.7096 - val_loss: 0.6096\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.6726 - loss: 0.5902 - val_accuracy: 0.7151 - val_loss: 0.5876\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.6999 - loss: 0.5712 - val_accuracy: 0.7151 - val_loss: 0.5608\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.7013 - loss: 0.5676 - val_accuracy: 0.7205 - val_loss: 0.5781\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.7095 - loss: 0.5536 - val_accuracy: 0.6849 - val_loss: 0.6178\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.7047 - loss: 0.5489 - val_accuracy: 0.5808 - val_loss: 0.6817\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.7109 - loss: 0.5441 - val_accuracy: 0.7205 - val_loss: 0.5622\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.7184 - loss: 0.5464 - val_accuracy: 0.7178 - val_loss: 0.5811\n",
            "    fold bal_acc=0.7229, prec=0.6385, rec=0.9432, f1=0.7615\n",
            "  Fold 5/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.5079 - loss: 0.7248 - val_accuracy: 0.6603 - val_loss: 0.7059\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.6015 - loss: 0.6676 - val_accuracy: 0.6301 - val_loss: 0.6112\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.7054 - loss: 0.5734 - val_accuracy: 0.6904 - val_loss: 0.5653\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.7307 - loss: 0.5368 - val_accuracy: 0.7370 - val_loss: 0.5233\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 69ms/step - accuracy: 0.7348 - loss: 0.5264 - val_accuracy: 0.7589 - val_loss: 0.5168\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.7457 - loss: 0.5100 - val_accuracy: 0.7644 - val_loss: 0.5086\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.7553 - loss: 0.5030 - val_accuracy: 0.7562 - val_loss: 0.5070\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.7573 - loss: 0.5022 - val_accuracy: 0.7425 - val_loss: 0.5219\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.7498 - loss: 0.5027 - val_accuracy: 0.7425 - val_loss: 0.5125\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.7642 - loss: 0.4985 - val_accuracy: 0.7589 - val_loss: 0.5069\n",
            "    fold bal_acc=0.7647, prec=0.6849, rec=0.9261, f1=0.7874\n",
            "\n",
            "=== Kernel run 5/9: conv1=(5, 5), conv2=(5, 5) ===\n",
            "  Fold 1/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.4993 - loss: 0.7215 - val_accuracy: 0.5191 - val_loss: 0.7041\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.5226 - loss: 0.6992 - val_accuracy: 0.5191 - val_loss: 0.6962\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.5451 - loss: 0.6939 - val_accuracy: 0.5191 - val_loss: 0.6919\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.5752 - loss: 0.6860 - val_accuracy: 0.5164 - val_loss: 0.6837\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.6115 - loss: 0.6716 - val_accuracy: 0.5164 - val_loss: 0.6723\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.6457 - loss: 0.6576 - val_accuracy: 0.5164 - val_loss: 0.6681\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6888 - loss: 0.6268 - val_accuracy: 0.6339 - val_loss: 0.6359\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.6799 - loss: 0.6238 - val_accuracy: 0.6831 - val_loss: 0.6134\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - accuracy: 0.6806 - loss: 0.6108 - val_accuracy: 0.6038 - val_loss: 0.6303\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.7031 - loss: 0.5863 - val_accuracy: 0.6694 - val_loss: 0.5828\n",
            "    fold bal_acc=0.6745, prec=0.6201, rec=0.8068, f1=0.7012\n",
            "  Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 131ms/step - accuracy: 0.5137 - loss: 0.7276 - val_accuracy: 0.4809 - val_loss: 0.7167\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.5876 - loss: 0.6706 - val_accuracy: 0.6721 - val_loss: 0.6425\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.6860 - loss: 0.5707 - val_accuracy: 0.6749 - val_loss: 0.5827\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.7141 - loss: 0.5510 - val_accuracy: 0.6557 - val_loss: 0.6439\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.7319 - loss: 0.5334 - val_accuracy: 0.6776 - val_loss: 0.5722\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.7428 - loss: 0.5238 - val_accuracy: 0.6913 - val_loss: 0.5941\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.7510 - loss: 0.5169 - val_accuracy: 0.6940 - val_loss: 0.5681\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.7490 - loss: 0.5099 - val_accuracy: 0.7404 - val_loss: 0.5350\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7558 - loss: 0.5113 - val_accuracy: 0.7432 - val_loss: 0.5309\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7565 - loss: 0.5089 - val_accuracy: 0.6557 - val_loss: 0.6349\n",
            "    fold bal_acc=0.7487, prec=0.6767, rec=0.8920, f1=0.7696\n",
            "  Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - accuracy: 0.4925 - loss: 0.7350 - val_accuracy: 0.5191 - val_loss: 0.7036\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.6122 - loss: 0.6754 - val_accuracy: 0.6885 - val_loss: 0.6280\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.6936 - loss: 0.6024 - val_accuracy: 0.7186 - val_loss: 0.5705\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.7209 - loss: 0.5729 - val_accuracy: 0.7568 - val_loss: 0.5553\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.7421 - loss: 0.5501 - val_accuracy: 0.7404 - val_loss: 0.5557\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.7401 - loss: 0.5418 - val_accuracy: 0.7404 - val_loss: 0.5468\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - accuracy: 0.7456 - loss: 0.5395 - val_accuracy: 0.7459 - val_loss: 0.5286\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.7524 - loss: 0.5213 - val_accuracy: 0.7705 - val_loss: 0.5168\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.7592 - loss: 0.5165 - val_accuracy: 0.7623 - val_loss: 0.5362\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.7510 - loss: 0.5155 - val_accuracy: 0.7596 - val_loss: 0.5091\n",
            "    fold bal_acc=0.7638, prec=0.7000, rec=0.8750, f1=0.7778\n",
            "  Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 109ms/step - accuracy: 0.5243 - loss: 0.7293 - val_accuracy: 0.5178 - val_loss: 0.7060\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6104 - loss: 0.6462 - val_accuracy: 0.5945 - val_loss: 0.5955\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6671 - loss: 0.5874 - val_accuracy: 0.7288 - val_loss: 0.5528\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.7054 - loss: 0.5559 - val_accuracy: 0.7288 - val_loss: 0.5233\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 99ms/step - accuracy: 0.7280 - loss: 0.5419 - val_accuracy: 0.7233 - val_loss: 0.5283\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.7334 - loss: 0.5384 - val_accuracy: 0.7370 - val_loss: 0.5103\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.7491 - loss: 0.5284 - val_accuracy: 0.7096 - val_loss: 0.5387\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - accuracy: 0.7573 - loss: 0.5203 - val_accuracy: 0.8110 - val_loss: 0.4877\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7614 - loss: 0.5138 - val_accuracy: 0.7671 - val_loss: 0.4944\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.7478 - loss: 0.5175 - val_accuracy: 0.7836 - val_loss: 0.4889\n",
            "    fold bal_acc=0.8145, prec=0.7488, rec=0.9148, f1=0.8235\n",
            "  Fold 5/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 109ms/step - accuracy: 0.5434 - loss: 0.6996 - val_accuracy: 0.6384 - val_loss: 0.6366\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6917 - loss: 0.5749 - val_accuracy: 0.7014 - val_loss: 0.5718\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 90ms/step - accuracy: 0.7006 - loss: 0.5525 - val_accuracy: 0.6849 - val_loss: 0.5696\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.7020 - loss: 0.5402 - val_accuracy: 0.7068 - val_loss: 0.5599\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7102 - loss: 0.5376 - val_accuracy: 0.7096 - val_loss: 0.5616\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 81ms/step - accuracy: 0.7232 - loss: 0.5265 - val_accuracy: 0.7068 - val_loss: 0.5525\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7198 - loss: 0.5297 - val_accuracy: 0.7068 - val_loss: 0.5626\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.7362 - loss: 0.5201 - val_accuracy: 0.7068 - val_loss: 0.5491\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.7389 - loss: 0.5128 - val_accuracy: 0.7068 - val_loss: 0.5401\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.7293 - loss: 0.5196 - val_accuracy: 0.7123 - val_loss: 0.5403\n",
            "    fold bal_acc=0.7158, prec=0.6273, rec=0.9659, f1=0.7606\n",
            "\n",
            "=== Kernel run 6/9: conv1=(5, 5), conv2=(7, 7) ===\n",
            "  Fold 1/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - accuracy: 0.5116 - loss: 0.7207 - val_accuracy: 0.5191 - val_loss: 0.6973\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.6245 - loss: 0.6647 - val_accuracy: 0.7186 - val_loss: 0.6031\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6984 - loss: 0.6016 - val_accuracy: 0.7268 - val_loss: 0.5620\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.7237 - loss: 0.5684 - val_accuracy: 0.6749 - val_loss: 0.6379\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.7606 - loss: 0.5254 - val_accuracy: 0.7842 - val_loss: 0.5097\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.7825 - loss: 0.4961 - val_accuracy: 0.8033 - val_loss: 0.4798\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.7839 - loss: 0.4892 - val_accuracy: 0.8005 - val_loss: 0.4699\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.7825 - loss: 0.4901 - val_accuracy: 0.7978 - val_loss: 0.4697\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.7825 - loss: 0.4784 - val_accuracy: 0.7869 - val_loss: 0.4810\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.8016 - loss: 0.4640 - val_accuracy: 0.7978 - val_loss: 0.4664\n",
            "    fold bal_acc=0.8021, prec=0.7318, rec=0.9148, f1=0.8131\n",
            "  Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 114ms/step - accuracy: 0.5096 - loss: 0.7232 - val_accuracy: 0.5628 - val_loss: 0.6842\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - accuracy: 0.6395 - loss: 0.6341 - val_accuracy: 0.6749 - val_loss: 0.5827\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - accuracy: 0.6874 - loss: 0.5855 - val_accuracy: 0.6721 - val_loss: 0.5694\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.7079 - loss: 0.5567 - val_accuracy: 0.6940 - val_loss: 0.5595\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6949 - loss: 0.5493 - val_accuracy: 0.6803 - val_loss: 0.5563\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.7209 - loss: 0.5384 - val_accuracy: 0.7049 - val_loss: 0.5373\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.7332 - loss: 0.5313 - val_accuracy: 0.6967 - val_loss: 0.5465\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 148ms/step - accuracy: 0.7326 - loss: 0.5234 - val_accuracy: 0.7213 - val_loss: 0.5417\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 314ms/step - accuracy: 0.7401 - loss: 0.5213 - val_accuracy: 0.6967 - val_loss: 0.5441\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 161ms/step - accuracy: 0.7538 - loss: 0.5105 - val_accuracy: 0.7350 - val_loss: 0.5274\n",
            "    fold bal_acc=0.7403, prec=0.6710, rec=0.8807, f1=0.7617\n",
            "  Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 245ms/step - accuracy: 0.5602 - loss: 0.7184 - val_accuracy: 0.5219 - val_loss: 0.6894\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - accuracy: 0.6908 - loss: 0.6287 - val_accuracy: 0.7514 - val_loss: 0.5284\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - accuracy: 0.7285 - loss: 0.5508 - val_accuracy: 0.7623 - val_loss: 0.5008\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - accuracy: 0.7572 - loss: 0.5212 - val_accuracy: 0.7650 - val_loss: 0.4841\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.7661 - loss: 0.5100 - val_accuracy: 0.7623 - val_loss: 0.4803\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.7633 - loss: 0.5019 - val_accuracy: 0.7650 - val_loss: 0.4826\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 117ms/step - accuracy: 0.7592 - loss: 0.5083 - val_accuracy: 0.7732 - val_loss: 0.4882\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 0.7613 - loss: 0.4960 - val_accuracy: 0.7596 - val_loss: 0.4793\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.7702 - loss: 0.5035 - val_accuracy: 0.7732 - val_loss: 0.4851\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 0.7695 - loss: 0.4928 - val_accuracy: 0.7978 - val_loss: 0.4649\n",
            "    fold bal_acc=0.8021, prec=0.7318, rec=0.9148, f1=0.8131\n",
            "  Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 159ms/step - accuracy: 0.5694 - loss: 0.6943 - val_accuracy: 0.7342 - val_loss: 0.6096\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 136ms/step - accuracy: 0.6815 - loss: 0.5823 - val_accuracy: 0.6685 - val_loss: 0.5491\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 159ms/step - accuracy: 0.6945 - loss: 0.5510 - val_accuracy: 0.7452 - val_loss: 0.5145\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.7300 - loss: 0.5321 - val_accuracy: 0.7397 - val_loss: 0.4868\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - accuracy: 0.7204 - loss: 0.5264 - val_accuracy: 0.7123 - val_loss: 0.5391\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.7239 - loss: 0.5327 - val_accuracy: 0.7699 - val_loss: 0.4717\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 0.7245 - loss: 0.5105 - val_accuracy: 0.7616 - val_loss: 0.4685\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 121ms/step - accuracy: 0.7368 - loss: 0.5155 - val_accuracy: 0.7781 - val_loss: 0.4739\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.7485 - loss: 0.5061 - val_accuracy: 0.7808 - val_loss: 0.4569\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - accuracy: 0.7464 - loss: 0.5107 - val_accuracy: 0.8164 - val_loss: 0.4632\n",
            "    fold bal_acc=0.7860, prec=0.7069, rec=0.9318, f1=0.8039\n",
            "  Fold 5/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 186ms/step - accuracy: 0.6220 - loss: 0.6626 - val_accuracy: 0.6986 - val_loss: 0.5893\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.6972 - loss: 0.5590 - val_accuracy: 0.7178 - val_loss: 0.5604\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.7075 - loss: 0.5430 - val_accuracy: 0.7096 - val_loss: 0.5574\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - accuracy: 0.7027 - loss: 0.5373 - val_accuracy: 0.7151 - val_loss: 0.5552\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.7239 - loss: 0.5298 - val_accuracy: 0.7205 - val_loss: 0.5483\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.7163 - loss: 0.5256 - val_accuracy: 0.7233 - val_loss: 0.5452\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 0.7252 - loss: 0.5289 - val_accuracy: 0.7260 - val_loss: 0.5479\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.7314 - loss: 0.5179 - val_accuracy: 0.7260 - val_loss: 0.5436\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.7273 - loss: 0.5139 - val_accuracy: 0.7342 - val_loss: 0.5442\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.7266 - loss: 0.5131 - val_accuracy: 0.7397 - val_loss: 0.5404\n",
            "    fold bal_acc=0.7477, prec=0.6552, rec=0.9716, f1=0.7826\n",
            "\n",
            "=== Kernel run 7/9: conv1=(7, 7), conv2=(3, 3) ===\n",
            "  Fold 1/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 223ms/step - accuracy: 0.5185 - loss: 0.7323 - val_accuracy: 0.6913 - val_loss: 0.7092\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - accuracy: 0.6094 - loss: 0.6827 - val_accuracy: 0.7158 - val_loss: 0.6242\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 239ms/step - accuracy: 0.6819 - loss: 0.6131 - val_accuracy: 0.7541 - val_loss: 0.5516\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - accuracy: 0.7114 - loss: 0.5536 - val_accuracy: 0.7760 - val_loss: 0.5194\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.7387 - loss: 0.5247 - val_accuracy: 0.7568 - val_loss: 0.4990\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.7291 - loss: 0.5197 - val_accuracy: 0.7732 - val_loss: 0.5044\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 146ms/step - accuracy: 0.7572 - loss: 0.5104 - val_accuracy: 0.7705 - val_loss: 0.4960\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 164ms/step - accuracy: 0.7510 - loss: 0.5038 - val_accuracy: 0.7596 - val_loss: 0.4884\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - accuracy: 0.7579 - loss: 0.5064 - val_accuracy: 0.7650 - val_loss: 0.4823\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 168ms/step - accuracy: 0.7476 - loss: 0.5101 - val_accuracy: 0.7377 - val_loss: 0.4978\n",
            "    fold bal_acc=0.7710, prec=0.6907, rec=0.9261, f1=0.7913\n",
            "  Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 274ms/step - accuracy: 0.5848 - loss: 0.7172 - val_accuracy: 0.6202 - val_loss: 0.6881\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 153ms/step - accuracy: 0.6621 - loss: 0.6420 - val_accuracy: 0.6831 - val_loss: 0.6186\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 161ms/step - accuracy: 0.6546 - loss: 0.6093 - val_accuracy: 0.6940 - val_loss: 0.5890\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - accuracy: 0.7066 - loss: 0.5682 - val_accuracy: 0.6885 - val_loss: 0.5674\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 165ms/step - accuracy: 0.7038 - loss: 0.5560 - val_accuracy: 0.6885 - val_loss: 0.5937\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 150ms/step - accuracy: 0.7298 - loss: 0.5400 - val_accuracy: 0.6967 - val_loss: 0.5698\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 119ms/step - accuracy: 0.7244 - loss: 0.5408 - val_accuracy: 0.6995 - val_loss: 0.5686\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.7312 - loss: 0.5309 - val_accuracy: 0.6858 - val_loss: 0.5914\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.7223 - loss: 0.5362 - val_accuracy: 0.6995 - val_loss: 0.5616\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.7326 - loss: 0.5210 - val_accuracy: 0.7049 - val_loss: 0.5540\n",
            "    fold bal_acc=0.7147, prec=0.6241, rec=0.9716, f1=0.7600\n",
            "  Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 218ms/step - accuracy: 0.5705 - loss: 0.7025 - val_accuracy: 0.7131 - val_loss: 0.6463\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 136ms/step - accuracy: 0.6464 - loss: 0.6252 - val_accuracy: 0.6995 - val_loss: 0.5782\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 166ms/step - accuracy: 0.6881 - loss: 0.5902 - val_accuracy: 0.7213 - val_loss: 0.5670\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.7079 - loss: 0.5606 - val_accuracy: 0.7131 - val_loss: 0.5340\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - accuracy: 0.7045 - loss: 0.5516 - val_accuracy: 0.7186 - val_loss: 0.5273\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 142ms/step - accuracy: 0.7073 - loss: 0.5432 - val_accuracy: 0.7213 - val_loss: 0.5275\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.7182 - loss: 0.5408 - val_accuracy: 0.7240 - val_loss: 0.5223\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 137ms/step - accuracy: 0.7223 - loss: 0.5302 - val_accuracy: 0.7186 - val_loss: 0.5126\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.7339 - loss: 0.5182 - val_accuracy: 0.7268 - val_loss: 0.5041\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - accuracy: 0.7428 - loss: 0.5206 - val_accuracy: 0.7514 - val_loss: 0.4957\n",
            "    fold bal_acc=0.7572, prec=0.6809, rec=0.9091, f1=0.7786\n",
            "  Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 126ms/step - accuracy: 0.5468 - loss: 0.7170 - val_accuracy: 0.7315 - val_loss: 0.6972\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step - accuracy: 0.6801 - loss: 0.6302 - val_accuracy: 0.6849 - val_loss: 0.6296\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.7211 - loss: 0.5565 - val_accuracy: 0.6575 - val_loss: 0.6372\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - accuracy: 0.7389 - loss: 0.5366 - val_accuracy: 0.7178 - val_loss: 0.5818\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.7382 - loss: 0.5279 - val_accuracy: 0.7205 - val_loss: 0.5752\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.7368 - loss: 0.5252 - val_accuracy: 0.7699 - val_loss: 0.5273\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 98ms/step - accuracy: 0.7471 - loss: 0.5232 - val_accuracy: 0.7644 - val_loss: 0.5234\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.7478 - loss: 0.5154 - val_accuracy: 0.6767 - val_loss: 0.5979\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.7621 - loss: 0.5048 - val_accuracy: 0.6247 - val_loss: 0.6510\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.7676 - loss: 0.4977 - val_accuracy: 0.6986 - val_loss: 0.5873\n",
            "    fold bal_acc=0.7703, prec=0.6875, rec=0.9375, f1=0.7933\n",
            "  Fold 5/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 125ms/step - accuracy: 0.5297 - loss: 0.7258 - val_accuracy: 0.5890 - val_loss: 0.7136\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 102ms/step - accuracy: 0.5694 - loss: 0.6909 - val_accuracy: 0.6685 - val_loss: 0.6577\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - accuracy: 0.6596 - loss: 0.6103 - val_accuracy: 0.6904 - val_loss: 0.5993\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - accuracy: 0.6801 - loss: 0.5769 - val_accuracy: 0.7068 - val_loss: 0.5865\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.6972 - loss: 0.5651 - val_accuracy: 0.7068 - val_loss: 0.5670\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.7054 - loss: 0.5501 - val_accuracy: 0.7123 - val_loss: 0.5641\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.7075 - loss: 0.5492 - val_accuracy: 0.7014 - val_loss: 0.5601\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - accuracy: 0.7143 - loss: 0.5349 - val_accuracy: 0.7096 - val_loss: 0.5572\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.7068 - loss: 0.5412 - val_accuracy: 0.7096 - val_loss: 0.5598\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.7109 - loss: 0.5345 - val_accuracy: 0.7151 - val_loss: 0.5512\n",
            "    fold bal_acc=0.7241, prec=0.6324, rec=0.9773, f1=0.7679\n",
            "\n",
            "=== Kernel run 8/9: conv1=(7, 7), conv2=(5, 5) ===\n",
            "  Fold 1/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 131ms/step - accuracy: 0.5027 - loss: 0.7135 - val_accuracy: 0.5027 - val_loss: 0.6712\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - accuracy: 0.6347 - loss: 0.6091 - val_accuracy: 0.6940 - val_loss: 0.6024\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.6758 - loss: 0.5751 - val_accuracy: 0.6885 - val_loss: 0.5865\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.7031 - loss: 0.5493 - val_accuracy: 0.6995 - val_loss: 0.6021\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.7155 - loss: 0.5379 - val_accuracy: 0.7049 - val_loss: 0.5635\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.7168 - loss: 0.5372 - val_accuracy: 0.7077 - val_loss: 0.5815\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - accuracy: 0.7237 - loss: 0.5269 - val_accuracy: 0.7104 - val_loss: 0.5493\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.7271 - loss: 0.5203 - val_accuracy: 0.7022 - val_loss: 0.5673\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.7264 - loss: 0.5257 - val_accuracy: 0.7049 - val_loss: 0.5786\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 125ms/step - accuracy: 0.7189 - loss: 0.5267 - val_accuracy: 0.7077 - val_loss: 0.5597\n",
            "    fold bal_acc=0.7198, prec=0.6296, rec=0.9659, f1=0.7623\n",
            "  Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 126ms/step - accuracy: 0.5787 - loss: 0.6924 - val_accuracy: 0.6803 - val_loss: 0.6421\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.6922 - loss: 0.5791 - val_accuracy: 0.6885 - val_loss: 0.5595\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - accuracy: 0.7127 - loss: 0.5508 - val_accuracy: 0.6858 - val_loss: 0.5472\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.7216 - loss: 0.5338 - val_accuracy: 0.6885 - val_loss: 0.5692\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.7223 - loss: 0.5286 - val_accuracy: 0.6995 - val_loss: 0.5427\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - accuracy: 0.7291 - loss: 0.5213 - val_accuracy: 0.6995 - val_loss: 0.5384\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.7278 - loss: 0.5132 - val_accuracy: 0.6776 - val_loss: 0.5907\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 103ms/step - accuracy: 0.7360 - loss: 0.5205 - val_accuracy: 0.6940 - val_loss: 0.5381\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.7326 - loss: 0.5266 - val_accuracy: 0.7022 - val_loss: 0.5366\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - accuracy: 0.7312 - loss: 0.5195 - val_accuracy: 0.7022 - val_loss: 0.5507\n",
            "    fold bal_acc=0.7100, prec=0.6314, rec=0.9148, f1=0.7471\n",
            "  Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 126ms/step - accuracy: 0.5424 - loss: 0.7279 - val_accuracy: 0.5683 - val_loss: 0.7149\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.5855 - loss: 0.6948 - val_accuracy: 0.5738 - val_loss: 0.6618\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - accuracy: 0.6546 - loss: 0.6208 - val_accuracy: 0.7213 - val_loss: 0.5752\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 98ms/step - accuracy: 0.6990 - loss: 0.5701 - val_accuracy: 0.7486 - val_loss: 0.5239\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - accuracy: 0.7285 - loss: 0.5427 - val_accuracy: 0.7432 - val_loss: 0.5068\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 161ms/step - accuracy: 0.7305 - loss: 0.5252 - val_accuracy: 0.7732 - val_loss: 0.4935\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.7579 - loss: 0.5080 - val_accuracy: 0.7732 - val_loss: 0.4944\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - accuracy: 0.7798 - loss: 0.5002 - val_accuracy: 0.8060 - val_loss: 0.4741\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.7784 - loss: 0.4909 - val_accuracy: 0.8115 - val_loss: 0.4695\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.7818 - loss: 0.4884 - val_accuracy: 0.8060 - val_loss: 0.4522\n",
            "    fold bal_acc=0.8106, prec=0.7354, rec=0.9318, f1=0.8221\n",
            "  Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 167ms/step - accuracy: 0.5639 - loss: 0.7150 - val_accuracy: 0.5836 - val_loss: 0.6763\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 146ms/step - accuracy: 0.6275 - loss: 0.6424 - val_accuracy: 0.7014 - val_loss: 0.5779\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.6863 - loss: 0.5743 - val_accuracy: 0.7233 - val_loss: 0.5295\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 139ms/step - accuracy: 0.6979 - loss: 0.5566 - val_accuracy: 0.7205 - val_loss: 0.5241\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 137ms/step - accuracy: 0.7068 - loss: 0.5499 - val_accuracy: 0.7233 - val_loss: 0.5482\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - accuracy: 0.7122 - loss: 0.5398 - val_accuracy: 0.7315 - val_loss: 0.5233\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 162ms/step - accuracy: 0.7177 - loss: 0.5385 - val_accuracy: 0.7288 - val_loss: 0.5309\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 180ms/step - accuracy: 0.7245 - loss: 0.5316 - val_accuracy: 0.7205 - val_loss: 0.5645\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 148ms/step - accuracy: 0.7239 - loss: 0.5387 - val_accuracy: 0.7342 - val_loss: 0.5208\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.7225 - loss: 0.5358 - val_accuracy: 0.7397 - val_loss: 0.5320\n",
            "    fold bal_acc=0.7432, prec=0.6458, rec=0.9943, f1=0.7830\n",
            "  Fold 5/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 211ms/step - accuracy: 0.5434 - loss: 0.7214 - val_accuracy: 0.5178 - val_loss: 0.6838\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 167ms/step - accuracy: 0.6418 - loss: 0.6389 - val_accuracy: 0.7014 - val_loss: 0.6091\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 148ms/step - accuracy: 0.6808 - loss: 0.5779 - val_accuracy: 0.7041 - val_loss: 0.5702\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - accuracy: 0.7088 - loss: 0.5542 - val_accuracy: 0.6986 - val_loss: 0.5648\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 147ms/step - accuracy: 0.7163 - loss: 0.5360 - val_accuracy: 0.7123 - val_loss: 0.5583\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 155ms/step - accuracy: 0.7198 - loss: 0.5349 - val_accuracy: 0.7123 - val_loss: 0.5615\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 127ms/step - accuracy: 0.7273 - loss: 0.5274 - val_accuracy: 0.7233 - val_loss: 0.5534\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 150ms/step - accuracy: 0.7382 - loss: 0.5194 - val_accuracy: 0.7288 - val_loss: 0.5565\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 151ms/step - accuracy: 0.7437 - loss: 0.5109 - val_accuracy: 0.7699 - val_loss: 0.5286\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 134ms/step - accuracy: 0.7731 - loss: 0.4936 - val_accuracy: 0.7479 - val_loss: 0.5308\n",
            "    fold bal_acc=0.7768, prec=0.6840, rec=0.9716, f1=0.8028\n",
            "\n",
            "=== Kernel run 9/9: conv1=(7, 7), conv2=(7, 7) ===\n",
            "  Fold 1/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 210ms/step - accuracy: 0.6088 - loss: 0.6651 - val_accuracy: 0.7186 - val_loss: 0.5740\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - accuracy: 0.6819 - loss: 0.5750 - val_accuracy: 0.7158 - val_loss: 0.5493\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.7148 - loss: 0.5508 - val_accuracy: 0.7213 - val_loss: 0.5402\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.7264 - loss: 0.5451 - val_accuracy: 0.7213 - val_loss: 0.5438\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 147ms/step - accuracy: 0.7196 - loss: 0.5390 - val_accuracy: 0.7240 - val_loss: 0.5413\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 153ms/step - accuracy: 0.7244 - loss: 0.5316 - val_accuracy: 0.7322 - val_loss: 0.5238\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 164ms/step - accuracy: 0.7285 - loss: 0.5240 - val_accuracy: 0.7295 - val_loss: 0.5350\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 201ms/step - accuracy: 0.7298 - loss: 0.5236 - val_accuracy: 0.7650 - val_loss: 0.5163\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 155ms/step - accuracy: 0.7531 - loss: 0.5160 - val_accuracy: 0.7568 - val_loss: 0.5012\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 169ms/step - accuracy: 0.7818 - loss: 0.4882 - val_accuracy: 0.7869 - val_loss: 0.4833\n",
            "    fold bal_acc=0.7916, prec=0.7188, rec=0.9148, f1=0.8050\n",
            "  Fold 2/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 226ms/step - accuracy: 0.5328 - loss: 0.7157 - val_accuracy: 0.7350 - val_loss: 0.6573\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 153ms/step - accuracy: 0.6566 - loss: 0.6143 - val_accuracy: 0.7322 - val_loss: 0.5399\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 163ms/step - accuracy: 0.7155 - loss: 0.5488 - val_accuracy: 0.7158 - val_loss: 0.5246\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 153ms/step - accuracy: 0.7394 - loss: 0.5224 - val_accuracy: 0.7268 - val_loss: 0.5116\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 139ms/step - accuracy: 0.7661 - loss: 0.5015 - val_accuracy: 0.7295 - val_loss: 0.5050\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 152ms/step - accuracy: 0.7572 - loss: 0.5053 - val_accuracy: 0.7923 - val_loss: 0.5019\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 135ms/step - accuracy: 0.7702 - loss: 0.5003 - val_accuracy: 0.7705 - val_loss: 0.4981\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 156ms/step - accuracy: 0.7845 - loss: 0.4844 - val_accuracy: 0.7486 - val_loss: 0.5143\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 149ms/step - accuracy: 0.7832 - loss: 0.4860 - val_accuracy: 0.7842 - val_loss: 0.4820\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.7832 - loss: 0.4759 - val_accuracy: 0.7022 - val_loss: 0.5245\n",
            "    fold bal_acc=0.7906, prec=0.7012, rec=0.9602, f1=0.8106\n",
            "  Fold 3/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 203ms/step - accuracy: 0.5205 - loss: 0.7161 - val_accuracy: 0.5191 - val_loss: 0.6985\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 147ms/step - accuracy: 0.5417 - loss: 0.6800 - val_accuracy: 0.6694 - val_loss: 0.6365\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 149ms/step - accuracy: 0.6512 - loss: 0.6054 - val_accuracy: 0.6967 - val_loss: 0.5605\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 153ms/step - accuracy: 0.6833 - loss: 0.5671 - val_accuracy: 0.6940 - val_loss: 0.5419\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 141ms/step - accuracy: 0.6874 - loss: 0.5631 - val_accuracy: 0.7186 - val_loss: 0.5438\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 224ms/step - accuracy: 0.7004 - loss: 0.5489 - val_accuracy: 0.7322 - val_loss: 0.5278\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.7059 - loss: 0.5497 - val_accuracy: 0.7350 - val_loss: 0.5277\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - accuracy: 0.7114 - loss: 0.5465 - val_accuracy: 0.7240 - val_loss: 0.5332\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 154ms/step - accuracy: 0.7127 - loss: 0.5390 - val_accuracy: 0.7186 - val_loss: 0.5237\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 136ms/step - accuracy: 0.7059 - loss: 0.5420 - val_accuracy: 0.7240 - val_loss: 0.5437\n",
            "    fold bal_acc=0.7264, prec=0.6431, rec=0.9318, f1=0.7610\n",
            "  Fold 4/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 215ms/step - accuracy: 0.5243 - loss: 0.7262 - val_accuracy: 0.6767 - val_loss: 0.7021\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 146ms/step - accuracy: 0.6118 - loss: 0.6568 - val_accuracy: 0.6658 - val_loss: 0.5800\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 153ms/step - accuracy: 0.6705 - loss: 0.5819 - val_accuracy: 0.7014 - val_loss: 0.6167\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 148ms/step - accuracy: 0.6801 - loss: 0.5760 - val_accuracy: 0.7123 - val_loss: 0.5740\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - accuracy: 0.6842 - loss: 0.5618 - val_accuracy: 0.7151 - val_loss: 0.5510\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 177ms/step - accuracy: 0.7081 - loss: 0.5507 - val_accuracy: 0.7315 - val_loss: 0.5291\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 141ms/step - accuracy: 0.6992 - loss: 0.5529 - val_accuracy: 0.7288 - val_loss: 0.5377\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - accuracy: 0.7033 - loss: 0.5483 - val_accuracy: 0.7233 - val_loss: 0.5455\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 100ms/step - accuracy: 0.7033 - loss: 0.5475 - val_accuracy: 0.7315 - val_loss: 0.5381\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.7150 - loss: 0.5325 - val_accuracy: 0.7315 - val_loss: 0.5169\n",
            "    fold bal_acc=0.7405, prec=0.6434, rec=0.9943, f1=0.7812\n",
            "  Fold 5/5\n",
            "Epoch 1/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 126ms/step - accuracy: 0.5427 - loss: 0.7051 - val_accuracy: 0.7068 - val_loss: 0.6301\n",
            "Epoch 2/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.6760 - loss: 0.5909 - val_accuracy: 0.7178 - val_loss: 0.5546\n",
            "Epoch 3/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.7020 - loss: 0.5486 - val_accuracy: 0.7205 - val_loss: 0.5488\n",
            "Epoch 4/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 108ms/step - accuracy: 0.7143 - loss: 0.5377 - val_accuracy: 0.7233 - val_loss: 0.5430\n",
            "Epoch 5/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - accuracy: 0.7314 - loss: 0.5280 - val_accuracy: 0.6438 - val_loss: 0.6393\n",
            "Epoch 6/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.7368 - loss: 0.5185 - val_accuracy: 0.7288 - val_loss: 0.5368\n",
            "Epoch 7/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.7286 - loss: 0.5202 - val_accuracy: 0.7342 - val_loss: 0.5377\n",
            "Epoch 8/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.7375 - loss: 0.5111 - val_accuracy: 0.7370 - val_loss: 0.5320\n",
            "Epoch 9/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - accuracy: 0.7485 - loss: 0.5037 - val_accuracy: 0.7315 - val_loss: 0.5425\n",
            "Epoch 10/10\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.7444 - loss: 0.4968 - val_accuracy: 0.7342 - val_loss: 0.5210\n",
            "    fold bal_acc=0.7426, prec=0.6491, rec=0.9773, f1=0.7800\n",
            "\n",
            "Grid search complete. Aggregated results saved to: kernel_search_results.csv\n",
            "  kernel_size_conv1 kernel_size_conv2  bal_acc_mean  bal_acc_std  \\\n",
            "0               3x3               7x7      0.773562     0.030604   \n",
            "1               5x5               7x7      0.775660     0.026597   \n",
            "2               7x7               7x7      0.758364     0.027318   \n",
            "3               7x7               5x5      0.752090     0.037233   \n",
            "4               3x3               5x5      0.753788     0.026222   \n",
            "5               7x7               3x3      0.747461     0.023609   \n",
            "6               5x5               3x3      0.749613     0.020932   \n",
            "7               5x5               5x5      0.743444     0.046947   \n",
            "8               3x3               3x3      0.717796     0.019081   \n",
            "\n",
            "   precision_mean  precision_std  recall_mean  recall_std   f1_mean    f1_std  \\\n",
            "0        0.695617       0.046359     0.936364    0.040878  0.795934  0.017272   \n",
            "1        0.699340       0.031372     0.922727    0.029545  0.794893  0.020007   \n",
            "2        0.671114       0.032297     0.955682    0.029061  0.787574  0.018074   \n",
            "3        0.665237       0.040181     0.955682    0.028613  0.783460  0.026955   \n",
            "4        0.671082       0.035551     0.943182    0.045026  0.782383  0.014688   \n",
            "5        0.663094       0.028769     0.944318    0.026260  0.778195  0.012931   \n",
            "6        0.676130       0.018856     0.902273    0.058432  0.771793  0.022438   \n",
            "7        0.674591       0.047685     0.890909    0.052000  0.766555  0.039200   \n",
            "8        0.625377       0.017078     0.984091    0.014102  0.764537  0.012030   \n",
            "\n",
            "   mean_train_epochs  \n",
            "0               10.0  \n",
            "1               10.0  \n",
            "2               10.0  \n",
            "3               10.0  \n",
            "4               10.0  \n",
            "5               10.0  \n",
            "6               10.0  \n",
            "7               10.0  \n",
            "8               10.0  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Grid search\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "all_results = []\n",
        "\n",
        "total_runs = len(KERNEL_SIZES) * len(KERNEL_SIZES)\n",
        "run_counter = 0\n",
        "\n",
        "for ks1, ks2 in [(a,b) for a in KERNEL_SIZES for b in KERNEL_SIZES]:\n",
        "    run_counter += 1\n",
        "    print(f\"\\n=== Kernel run {run_counter}/{total_runs}: conv1={ks1}, conv2={ks2} ===\")\n",
        "\n",
        "    # Collect fold metrics\n",
        "    fold_bal_acc = []\n",
        "    fold_prec = []\n",
        "    fold_rec = []\n",
        "    fold_f1 = []\n",
        "    fold_epochs = []\n",
        "\n",
        "    fold_idx = 0\n",
        "    for train_idx, val_idx in skf.split(X, y):\n",
        "        fold_idx += 1\n",
        "        print(f\"  Fold {fold_idx}/{N_SPLITS}\")\n",
        "\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        # Keras expects categorical labels\n",
        "        y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "        y_val_cat = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
        "\n",
        "        # Build model for this fold\n",
        "        model = build_model(kernel_size_1=ks1, kernel_size_2=ks2, input_shape=X_train.shape[1:], dropout_p=DROPOUT_P)\n",
        "\n",
        "        # Callbacks\n",
        "        es = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0)\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train, y_train_cat,\n",
        "            validation_data=(X_val, y_val_cat),\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            callbacks=[es],\n",
        "            verbose=VERBOSE\n",
        "        )\n",
        "\n",
        "        fold_epochs.append(len(history.history['loss']))\n",
        "\n",
        "        # Predict\n",
        "        y_pred_prob = model.predict(X_val, verbose=0)\n",
        "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "        # Compute metrics (binary averaging; positive label = POS_LABEL)\n",
        "        bal_acc = balanced_accuracy_score(y_val, y_pred)\n",
        "        prec = precision_score(y_val, y_pred, pos_label=POS_LABEL, zero_division=0)\n",
        "        rec = recall_score(y_val, y_pred, pos_label=POS_LABEL, zero_division=0)\n",
        "        f1 = f1_score(y_val, y_pred, pos_label=POS_LABEL, zero_division=0)\n",
        "\n",
        "        print(f\"    fold bal_acc={bal_acc:.4f}, prec={prec:.4f}, rec={rec:.4f}, f1={f1:.4f}\")\n",
        "\n",
        "        fold_bal_acc.append(bal_acc)\n",
        "        fold_prec.append(prec)\n",
        "        fold_rec.append(rec)\n",
        "        fold_f1.append(f1)\n",
        "\n",
        "        # Clean up to reduce GPU memory growth between folds\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    # Aggregate per kernel combo (mean + std)\n",
        "    result = {\n",
        "        \"kernel_size_conv1\": f\"{ks1[0]}x{ks1[1]}\",\n",
        "        \"kernel_size_conv2\": f\"{ks2[0]}x{ks2[1]}\",\n",
        "        \"bal_acc_mean\": float(np.mean(fold_bal_acc)),\n",
        "        \"bal_acc_std\": float(np.std(fold_bal_acc)),\n",
        "        \"precision_mean\": float(np.mean(fold_prec)),\n",
        "        \"precision_std\": float(np.std(fold_prec)),\n",
        "        \"recall_mean\": float(np.mean(fold_rec)),\n",
        "        \"recall_std\": float(np.std(fold_rec)),\n",
        "        \"f1_mean\": float(np.mean(fold_f1)),\n",
        "        \"f1_std\": float(np.std(fold_f1)),\n",
        "        \"mean_train_epochs\": float(np.mean(fold_epochs))\n",
        "    }\n",
        "    all_results.append(result)\n",
        "\n",
        "# Save to disk\n",
        "df = pd.DataFrame(all_results)\n",
        "df = df.sort_values(by=\"f1_mean\", ascending=False).reset_index(drop=True)\n",
        "df.to_csv(RESULTS_CSV, index=False)\n",
        "print(f\"\\nGrid search complete. Aggregated results saved to: {RESULTS_CSV}\")\n",
        "print(df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.11.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
